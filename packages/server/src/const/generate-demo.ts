// ğŸ› ï¸ å·¥å…·è°ƒç”¨ API
// 4. Tools & Function Calling
import { createOpenAI } from '@ai-sdk/openai';
import { generateText, streamText, generateObject } from 'ai';
import { z } from 'zod';
import { Hono } from 'hono';
import { logger } from '../utils/log';

const openaiSdk = createOpenAI({
  apiKey: process.env.FRIDAY_API_KEY,
  baseURL: 'https://aigc.sankuai.com/v1/openai/native/',
});

const app = new Hono();

// å®šä¹‰å·¥å…·
const weatherTool = {
  description: 'è·å–å¤©æ°”ä¿¡æ¯',
  parameters: z.object({
    city: z.string().describe('åŸå¸‚åç§°'),
  }),
  execute: async ({ city }: { city: string }) => {
    // æ¨¡æ‹Ÿå¤©æ°”APIè°ƒç”¨
    return {
      city,
      temperature: Math.floor(Math.random() * 30) + 10,
      condition: 'æ™´å¤©',
    };
  },
};

// ä½¿ç”¨å·¥å…·çš„å¯¹è¯
app.post('/api/chat-with-tools', async (c) => {
  const { message } = await c.req.json();
  const result = await generateText({
    model: openaiSdk('gpt-4o-mini'),
    tools: {
      getWeather: weatherTool,
    },
    messages: [{ role: 'user', content: message }],
  });

  return c.json({ response: result.text });
});

// æµå¼å·¥å…·è°ƒç”¨
export async function streamTextWithToolsDemo(prompt: string) {
  const result = await streamText({
    model: openaiSdk('gpt-4o-mini'),
    tools: {
      getWeather: weatherTool,
      getTime: {
        description: 'è·å–å½“å‰æ—¶é—´',
        parameters: z.object({}),
        execute: async () => ({ time: new Date().toISOString() }),
      },
    },
    prompt: 'ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿç°åœ¨å‡ ç‚¹äº†ï¼Ÿ',
    onChunk({ chunk }) {
      if (chunk.type === 'tool-call') {
        console.log('è°ƒç”¨å·¥å…·:', chunk.toolName, chunk.args);
      }
    },
  });
}

/**
 * ğŸ’¬ å¯¹è¯ç®¡ç† API
 * 5. Messages & Chat History
 */
// å¤šè½®å¯¹è¯
app.post('/api/chat-conversation', async (c) => {
  const { messages, newMessage } = await c.req.json();

  const conversationMessages = [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹' },
    ...messages, // å†å²æ¶ˆæ¯
    { role: 'user', content: newMessage },
  ];

  const result = await streamText({
    model: openaiSdk('gpt-4o-mini'),
    messages: conversationMessages,
  });

  // è®¾ç½®SSEå“åº”
  c.header('Content-Type', 'text/event-stream');

  for await (const textPart of result.textStream) {
    c.write(`data: ${JSON.stringify({ content: textPart })}\n\n`);
  }

  c.write('data: [DONE]\n\n');
  c.end();
});

// å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯
export async function generateTextWithContextDemo(prompt: string) {
  const { text } = await generateText({
    model: openaiSdk('gpt-4o-mini'),
    messages: [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä»£ç å®¡æŸ¥ä¸“å®¶' },
      { role: 'user', content: 'è¿™æ®µä»£ç æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ' },
      { role: 'user', content: 'function add(a, b) { return a + b }' },
    ],
  });
}

/**
 * âš™ï¸ é…ç½®å’Œé”™è¯¯å¤„ç†
6. Provider Configuration
 */

// å¤šæ¨¡å‹é…ç½®
const openaiProvider = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: 'https://aigc.sankuai.com/v1/openai/native/',
});

const anthropicProvider = createAnthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// åŠ¨æ€é€‰æ‹©æ¨¡å‹
app.post('/api/smart-chat', async (req, res) => {
  const { message, modelType = 'openai' } = req.body;

  const model =
    modelType === 'openai'
      ? openaiProvider('gpt-4o-mini')
      : anthropicProvider('claude-3-sonnet-20240229');

  const { text } = await generateText({
    model,
    prompt: message,
  });

  res.json({ response: text, usedModel: modelType });
});

// é”™è¯¯å¤„ç†å’Œé‡è¯•
app.post('/api/robust-chat', async (c) => {
  const { message } = await c.req.json();

  try {
    const { text } = await generateText({
      model: openaiSdk('gpt-4o-mini'),
      prompt: message,
      maxRetries: 3, // è‡ªåŠ¨é‡è¯•
      abortSignal: AbortSignal.timeout(30000), // 30ç§’è¶…æ—¶
    });

    return c.json({ response: text });
  } catch (error) {
    if (error instanceof Error && error.name === 'AbortError') {
      return c.status(408).json({ error: 'è¯·æ±‚è¶…æ—¶' });
    } else {
      return c.status(500).json({ error: 'AIæœåŠ¡å¼‚å¸¸' });
    }
  }
});

/**
 * ğŸ“Š ä½¿ç”¨ç›‘æ§å’Œè°ƒè¯•
 * 7. Usage Tracking & Debugging
 */

// ä½¿ç”¨ç›‘æ§
// ç›‘æ§Tokenä½¿ç”¨
export async function generateTextWithUsageTrackingDemo(prompt: string) {
  const result = await generateText({
    model: openaiSdk('gpt-4o-mini'),
    prompt: 'å†™ä¸€ç¯‡å…³äºAIçš„æ–‡ç« ',
    onFinish({ usage, text }) {
      console.log('Tokenä½¿ç”¨æƒ…å†µ:', {
        prompt: usage.promptTokens,
        completion: usage.completionTokens,
        total: usage.totalTokens,
      });

      // è®°å½•åˆ°æ•°æ®åº“æˆ–ç›‘æ§ç³»ç»Ÿ
      logger.info({
        type: 'ai-usage',
        tokens: usage.totalTokens,
        model: 'gpt-4o-mini',
        responseLength: text.length,
      });
    },
  });

  return result;
}

// æµå¼ç›‘æ§
export async function streamTextWithUsageTrackingDemo(prompt: string) {
  const result = await streamText({
    model: openaiSdk('gpt-4o-mini'),
    prompt: 'è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—',
    experimental_telemetry: {
      isEnabled: true,
      functionId: 'quantum-explanation',
    },
    onChunk({ chunk }) {
      // å®æ—¶ç›‘æ§
      console.log('Chunk received:', chunk.text?.length || 0, 'chars');
    },
    onFinish({ usage }) {
      console.log('Stream finished, total tokens:', usage.totalTokens);
    },
  });
  return result;
}

/**
 * ğŸ” é«˜çº§åŠŸèƒ½
 * 8. Advanced Features
 */

// ä½¿ç”¨ä»£ç†
export async function generateTextWithProxyDemo(prompt: string) {
  const result = await generateText({
    model: openaiSdk('gpt-4o-mini'),
    prompt: 'å†™ä¸€ç¯‡å…³äºAIçš„æ–‡ç« ',
  });
  return result;
}
